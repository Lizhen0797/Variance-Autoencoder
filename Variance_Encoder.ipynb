{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Encoder有两个层，一个用于计算隐藏层分布的均值，另一个用于提取隐藏层的方差，并通过这两个变量转换为隐藏向量的数据，通过随机生成正态分布并平移得到，因此该生成的z基本是不可复现的。\n",
    "\n",
    "ncoder has two layers, one is used to calculate the mean value of hidden layer distribution, and the other is used to calculate the variance of hidden layer, which is transformed into hidden vector data by these two variables, and is obtained by randomly generating normal distribution and translation. Therefore, the generated Z is basically non reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    随机采样, 保证latent vector的分布为正态分布\n",
    "    @inputs latent vector通过神经网络生成的 均值(z_mean)和方差(z_log_var) 采用log的原因是nn生成的可正可负而方差只能为正，所以采用log\n",
    "    @return z 符合z_mean和z_log_var的正态分布的z的随机生成z\n",
    "    \n",
    "    Random Sampling, ensure that the distribution of late vector is normal distribution\n",
    "    @inputs The mean value and variance in log of z generated by the neural network,\n",
    "    The reason why log is used in var is that NN can generate positive and negative data, but variance can only be positive, \n",
    "    so log is used to avoid it.\n",
    "    @return z In accordance with mean and variance normal distribution variable random generation Z\n",
    "    '''\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        # 使得生成的分布满足(z_mean, z_log) 参见正态分布的性质\n",
    "        return z_mean + tf.exp(0.5*z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    VAE的encoder\n",
    "    @param latent_dim z的向量大小\n",
    "    @param intermediate_dim 中间层的向量大小\n",
    "    \n",
    "    @return z_mean, z_log_var, z z的均值, z的log方差, 符合正态分布的随机取样z\n",
    "    \n",
    "    The encoder of VAE\n",
    "    @param latent_dim z‘s dim\n",
    "    @param intermediate_dim middle layer's dim\n",
    "    \n",
    "    @return z_mean, z_log_var, z z's mean , z's variance in log, random sampling of z in normal distribution\n",
    "    '''\n",
    "    def __init__(self, latent_dim, intermediate_dim, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "        self.intermediate = tf.keras.layers.Dense(intermediate_dim, activation='relu')\n",
    "        # a layer for generation z's mean\n",
    "        # 用于生成z的均值\n",
    "        self.mean = tf.keras.layers.Dense(latent_dim)\n",
    "        # a layer for generation z's log variance\n",
    "        # 用于生成z的log 方差\n",
    "        self.log_var = tf.keras.layers.Dense(latent_dim)\n",
    "        # Random Sampling of Z in normal distribution\n",
    "        # z的正态分布随机生取样\n",
    "        self.sample =Sampling()\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.intermediate(inputs)\n",
    "        z_mean = self.mean(x)\n",
    "        z_log_var = self.log_var(x)\n",
    "        z = self.sample([z_mean, z_log_var])\n",
    "        \n",
    "        return z_mean, z_log_var, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    VAE的deocder\n",
    "    @param original_dim 原始向量大小\n",
    "    @param intermediate_dim 中间层的向量大小\n",
    "    \n",
    "    @return 原始向量\n",
    "    \n",
    "    The decoder of VAE\n",
    "    @param original_dim original vector's dim\n",
    "    @param intermediate_dim middle layer's dim\n",
    "    \n",
    "    @return original dim\n",
    "    '''\n",
    "    def __init__(self, original_dim, intermediate_dim, **kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "        self.intermediate = tf.keras.layers.Dense(intermediate_dim, activation='relu')\n",
    "        self.outputs = tf.keras.layers.Dense(original_dim, activation='sigmoid')\n",
    "    def call(self, inputs):\n",
    "        x = self.intermediate(inputs)\n",
    "        return self.outputs(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL_DIM=3294\n",
    "INTERMEDIATE_DIM=1024\n",
    "LATTENT_DIM=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    vae_input = tf.keras.layers.Input((ORIGINAL_DIM,))\n",
    "    z_mean, z_log_var, z = Encoder(LATTENT_DIM, INTERMEDIATE_DIM)(vae_input)\n",
    "    reconstruct_x = Decoder(ORIGINAL_DIM, INTERMEDIATE_DIM)(z)\n",
    "    # reconstruct loss function of generation and original, mean squared erros is used because of continous variable generation.\n",
    "    # 原始数据和生成数据的重构误差，因为为连续值生成所以使用了均方差\n",
    "    reconstruction_loss = tf.keras.losses.mean_squared_error(vae_input, reconstruct_x)\n",
    "    # KL loss\n",
    "    # KL loss\n",
    "    kl_loss = -0.5 * tf.keras.backend.sum(1 + z_log_var - tf.keras.backend.square(z_mean) - tf.keras.backend.exp(z_log_var), axis=-1)\n",
    "    elbo = tf.keras.backend.mean(reconstruction_loss+kl_loss)\n",
    "    #elbo = -1 *elbo\n",
    "    model = tf.keras.models.Model(vae_input, reconstruct_x)\n",
    "    model.add_loss(elbo)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n"
     ]
    }
   ],
   "source": [
    "vae = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 3294)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1 (Encoder)             ((None, 512), (None, 4423680     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Decoder)               (None, 3294)         3901662     encoder_1[0][2]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add (TensorFlowOpLa [(None, 512)]        0           encoder_1[0][1]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Square (TensorFlowO [(None, 512)]        0           encoder_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_sub (TensorFlowOpLa [(None, 512)]        0           tf_op_layer_add[0][0]            \n",
      "                                                                 tf_op_layer_Square[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Exp (TensorFlowOpLa [(None, 512)]        0           encoder_1[0][1]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_sub_1 (TensorFlowOp [(None, 512)]        0           tf_op_layer_sub[0][0]            \n",
      "                                                                 tf_op_layer_Exp[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_SquaredDifference ( [(None, 3294)]       0           decoder[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum (TensorFlowOpLa [(None,)]            0           tf_op_layer_sub_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean (TensorFlowOpL [(None,)]            0           tf_op_layer_SquaredDifference[0][\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul (TensorFlowOpLa [(None,)]            0           tf_op_layer_Sum[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_1 (TensorFlowOp [(None,)]            0           tf_op_layer_Mean[0][0]           \n",
      "                                                                 tf_op_layer_mul[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean_1 (TensorFlowO [()]                 0           tf_op_layer_add_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_loss (AddLoss)              ()                   0           tf_op_layer_Mean_1[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 8,325,342\n",
      "Trainable params: 8,325,342\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "如果想使用encoder的输出\n",
    "if you want to get the output of encoder, you can use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_output = vae.layers[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
